{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 3: RBF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Importamos las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Recogemos los datos de entrada para configurar la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data =pd.read_csv(\"basesDatosPr3IMC/csv/train_vote.csv\", header=None)\n",
    "test_data = pd.read_csv(\"basesDatosPr3IMC/csv/test_vote.csv\", header = None)\n",
    "l2 = True\n",
    "ratio_rbf = 0.3\n",
    "eta = 10**-5\n",
    "classification = False\n",
    "outputs = 1\n",
    "porcentaje_neuronas = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Declaramos el main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "Semilla: 100\n",
      "-----------\n",
      "Número de RBFs utilizadas: 98\n",
      "El numero de centros usados:  98\n",
      "El numero de distancias existentes es:  326\n",
      "MSE de entrenamiento: 0.017053\n",
      "MSE de test: 0.049492\n",
      "-----------\n",
      "Semilla: 200\n",
      "-----------\n",
      "Número de RBFs utilizadas: 98\n",
      "El numero de centros usados:  98\n",
      "El numero de distancias existentes es:  326\n",
      "MSE de entrenamiento: 0.012570\n",
      "MSE de test: 0.046376\n",
      "-----------\n",
      "Semilla: 300\n",
      "-----------\n",
      "Número de RBFs utilizadas: 98\n",
      "El numero de centros usados:  98\n",
      "El numero de distancias existentes es:  326\n",
      "MSE de entrenamiento: 0.013825\n",
      "MSE de test: 0.044510\n",
      "-----------\n",
      "Semilla: 400\n",
      "-----------\n",
      "Número de RBFs utilizadas: 98\n",
      "El numero de centros usados:  98\n",
      "El numero de distancias existentes es:  326\n",
      "MSE de entrenamiento: 0.015720\n",
      "MSE de test: 0.044486\n",
      "-----------\n",
      "Semilla: 500\n",
      "-----------\n",
      "Número de RBFs utilizadas: 98\n",
      "El numero de centros usados:  98\n",
      "El numero de distancias existentes es:  326\n",
      "MSE de entrenamiento: 0.015434\n",
      "MSE de test: 0.048989\n",
      "\n",
      "*********************\n",
      "Resumen de resultados\n",
      "*********************\n",
      "MSE de entrenamiento: 0.014920 +- 0.001561\n",
      "MSE de test: 0.046771 +- 0.002136\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    entrenar_rbf_total(train_data, test_data, classification, ratio_rbf, l2, eta, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Declaramos la función entrenar_rbf_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_rbf_total(train_data, test_data, classification, ratio_rbf, l2, eta, outputs):\n",
    "    \"\"\" Modelo de aprendizaje supervisado mediante red neuronal de tipo RBF.\n",
    "        Ejecución de 5 semillas.\n",
    "    \"\"\"\n",
    "    train_mses = np.empty(5)\n",
    "    train_ccrs = np.empty(5)\n",
    "    test_mses = np.empty(5)\n",
    "    test_ccrs = np.empty(5)\n",
    "\n",
    "    for s in range(100,600,100):   \n",
    "        print(\"-----------\")\n",
    "        print(\"Semilla: %d\" % s)\n",
    "        print(\"-----------\")     \n",
    "        np.random.seed(s)\n",
    "        train_mses[s//100-1], test_mses[s//100-1], train_ccrs[s//100-1], test_ccrs[s//100-1], matriz_confusion = \\\n",
    "            entrenar_rbf(train_data, test_data, classification, ratio_rbf, l2, eta, outputs)\n",
    "        print(\"MSE de entrenamiento: %f\" % train_mses[s//100-1])\n",
    "        print(\"MSE de test: %f\" % test_mses[s//100-1])\n",
    "        if classification:\n",
    "            print(\"CCR de entrenamiento: %.2f%%\" % train_ccrs[s//100-1])\n",
    "            print(\"CCR de test: %.2f%%\" % test_ccrs[s//100-1])\n",
    "    \n",
    "    print(\"\\n*********************\")\n",
    "    print(\"Resumen de resultados\")\n",
    "    print(\"*********************\")\n",
    "    print(\"MSE de entrenamiento: %f +- %f\" % (np.mean(train_mses), np.std(train_mses)))\n",
    "    print(\"MSE de test: %f +- %f\" % (np.mean(test_mses), np.std(test_mses)))\n",
    "    if classification:\n",
    "        print(\"CCR de entrenamiento: %.2f%% +- %.2f%%\" % (np.mean(train_ccrs), np.std(train_ccrs)))\n",
    "        print(\"CCR de test: %.2f%% +- %.2f%%\" % (np.mean(test_ccrs), np.std(test_ccrs)))\n",
    "        print(\"La matriz de confusión es la siguiente:\")\n",
    "        print(matriz_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Delaramos la cunción entrenar_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_rbf(train_data, test_data, classification, ratio_rbf, l2, eta, outputs):\n",
    "    \"\"\" Modelo de aprendizaje supervisado mediante red neuronal de tipo RBF.\n",
    "        Una única ejecución.\n",
    "        Recibe los siguientes parámetros:\n",
    "            - train_file: nombre del fichero de entrenamiento.\n",
    "            - test_file: nombre del fichero de test.\n",
    "            - classification: True si el problema es de clasificacion.\n",
    "            - ratio_rbf: Ratio (en tanto por uno) de neuronas RBF con \n",
    "              respecto al total de patrones.\n",
    "            - l2: True si queremos utilizar L2 para la Regresión Logística. \n",
    "              False si queremos usar L1 (para regresión logística).\n",
    "            - eta: valor del parámetro de regularización para la Regresión \n",
    "              Logística.\n",
    "            - outputs: número de variables que se tomarán como salidas \n",
    "              (todas al final de la matriz).\n",
    "        Devuelve:\n",
    "            - train_mse: Error de tipo Mean Squared Error en entrenamiento. \n",
    "              En el caso de clasificación, calcularemos el MSE de las \n",
    "              probabilidades predichas frente a las objetivo.\n",
    "            - test_mse: Error de tipo Mean Squared Error en test. \n",
    "              En el caso de clasificación, calcularemos el MSE de las \n",
    "              probabilidades predichas frente a las objetivo.\n",
    "            - train_ccr: Error de clasificación en entrenamiento. \n",
    "              En el caso de regresión, devolvemos un cero.\n",
    "            - test_ccr: Error de clasificación en test. \n",
    "              En el caso de regresión, devolvemos un cero.\n",
    "    \"\"\"\n",
    "    train_inputs, train_outputs, test_inputs, test_outputs = lectura_datos(train_data, test_data, outputs)\n",
    "\n",
    "    #TODO: Obtener num_rbf a partir de ratio_rbf\n",
    "    num_rbfs=int(round(ratio_rbf*len(train_inputs)))  #Multiplicar el ratio por el numero de patrones de train\n",
    "    print(\"Número de RBFs utilizadas: %d\" %(num_rbfs))\n",
    "\n",
    "    kmedias, distancias, centros = clustering(classification, train_inputs, train_outputs, num_rbfs)\n",
    "    radios = calcular_radios(centros, num_rbfs)\n",
    "    matriz_r = calcular_matriz_r(distancias, radios)\n",
    "    \n",
    "    if not classification:\n",
    "        coefficients = invertir_matriz_regresion(matriz_r, train_outputs)\n",
    "    else:\n",
    "        logreg = logreg_clasificacion(matriz_r, train_outputs, eta, l2)\n",
    "\n",
    "    \"\"\"\n",
    "    TODO: Calcular las distancias de los centroides a los patrones de test\n",
    "          y la matriz R de test\n",
    "    \"\"\"\n",
    "    distancias_test = kmedias.transform(test_inputs)\n",
    "    matriz_r_test = calcular_matriz_r(distancias_test, radios)\n",
    "    \n",
    "    if not classification:\n",
    "        \"\"\"\n",
    "        TODO: Obtener las predicciones de entrenamiento y de test y calcular\n",
    "              el MSE\n",
    "        \"\"\"\n",
    "        predicted_test_a = np.dot(matriz_r_test, coefficients)\n",
    "        predicted_train_a = np.dot(matriz_r, coefficients)\n",
    "        \n",
    "        predicted_test= np.round(predicted_test_a)\n",
    "        predicted_train= np.round(predicted_train_a) \n",
    "        \n",
    "        predicted_test += 0.\n",
    "        predicted_train += 0.\n",
    "        \n",
    "        test_mse = mean_squared_error(test_outputs, predicted_test_a)\n",
    "        train_mse = mean_squared_error(train_outputs, predicted_train_a)\n",
    "        \n",
    "        train_ccr = 0\n",
    "        test_ccr = 0\n",
    "        matriz_confusion = np.ones(predicted_train.shape)\n",
    "    else:\n",
    "        \"\"\"\n",
    "        TODO: Obtener las predicciones de entrenamiento y de test y calcular\n",
    "              el CCR. Calcular también el MSE, comparando las probabilidades \n",
    "              obtenidas y las probabilidades objetivo\n",
    "        \"\"\"\n",
    "        predicted_train = logreg.predict(matriz_r)\n",
    "        predicted_test = logreg.predict(matriz_r_test)\n",
    "        \n",
    "        train_mse = mean_squared_error(predicted_train, train_outputs)\n",
    "        test_mse = mean_squared_error(predicted_test, test_outputs)\n",
    "        \n",
    "        train_ccr = logreg.score(matriz_r, train_outputs)*100\n",
    "        test_ccr = logreg.score(matriz_r_test, test_outputs)*100\n",
    "        \n",
    "        #Mostramos la matriz de confusion\n",
    "        matriz_confusion = confusion_matrix(test_outputs, predicted_test)\n",
    "       \n",
    "    return train_mse, test_mse, train_ccr, test_ccr, matriz_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Declaramos la función para leer los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lectura_datos(train_data, test_data, outputs):\n",
    "    \"\"\" Realiza la lectura de datos.\n",
    "        Recibe los siguientes parámetros:\n",
    "            - fichero_train: nombre del fichero de entrenamiento.\n",
    "            - fichero_test: nombre del fichero de test.\n",
    "            - outputs: número de variables que se tomarán como salidas \n",
    "              (todas al final de la matriz).\n",
    "        Devuelve:\n",
    "            - train_inputs: matriz con las variables de entrada de \n",
    "              entrenamiento.\n",
    "            - train_outputs: matriz con las variables de salida de \n",
    "              entrenamiento.\n",
    "            - test_inputs: matriz con las variables de entrada de \n",
    "              test.\n",
    "            - test_outputs: matriz con las variables de salida de \n",
    "              test.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_inputs = train_data.values[:, 0:-outputs];\n",
    "    train_outputs = train_data.values[:, -outputs];#Guarda las clases existentes\n",
    "\n",
    "    test_inputs = test_data.values[:, 0:-outputs];\n",
    "    test_outputs = test_data.values[:, -outputs];\n",
    "    #TODO: Completar el código de la función\n",
    "    return train_inputs, train_outputs, test_inputs, test_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Declaramos la función clustering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar el clustering, vamos primero a inicializar los centros. Si se trata de un problema de clasificación, dividiremos los centros de una manera estratificada. En caso contrario, es decir, en regresión, inicializaremos los centros de manera aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(clasificacion, train_inputs, train_outputs, num_rbfs):\n",
    "    if classification == True:\n",
    "        centros = inicializar_centroides_clas(train_inputs, train_outputs, num_rbfs)\n",
    "    else:\n",
    "        centros = train_inputs[np.random.choice(train_inputs.shape[0], num_rbfs, replace=False), :]\n",
    "    \n",
    "    kmedias = KMeans(n_init=1, max_iter=500, n_clusters=num_rbfs, init=centros).fit(train_inputs)\n",
    "    centros = kmedias.cluster_centers_\n",
    "    print(\"El numero de centros usados: \", len(centros))\n",
    "    distancias = kmedias.transform(train_inputs)\n",
    "    print(\"El numero de distancias existentes es: \", len(distancias))\n",
    "    \n",
    "    return kmedias, distancias, centros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Declaramos la función para inicializar los centros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta función utilizaremos la función proporcionada por scklearn llamada StratifiedShuffleSplit, la cual inicializa los centros de manera estratificada. Para ello, elegimos el número de iteraciones para "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicializar_centroides_clas(train_inputs, train_outputs, num_rbfs):\n",
    "    \"\"\" Inicializa los centroides para el caso de clasificación.\n",
    "        Debe elegir los patrones de forma estratificada, manteniendo\n",
    "        la proporción de patrones por clase.\n",
    "        Recibe los siguientes parámetros:\n",
    "            - train_inputs: matriz con las variables de entrada de \n",
    "              entrenamiento.\n",
    "            - train_outputs: matriz con las variables de salida de \n",
    "              entrenamiento.\n",
    "            - num_rbf: número de neuronas de tipo RBF.\n",
    "        Devuelve:\n",
    "            - centroides: matriz con todos los centroides iniciales\n",
    "                          (num_rbf x num_entradas).\n",
    "    \"\"\"\n",
    "    \n",
    "    #TODO: Completar el código de la función\n",
    "    sss = StratifiedShuffleSplit(train_outputs, n_iter=10, train_size=num_rbfs, test_size=None)\n",
    "    print(train_inputs)\n",
    "    for train_index, test_index in sss:\n",
    "        centroides = train_inputs[train_index,:]\n",
    "    \n",
    "    indice = 0\n",
    "   \n",
    "    while centroides.shape[0] < num_rbfs:        \n",
    "        centroides = np.r_[centroides, [train_inputs[test_index[indice]]]] \n",
    "        indice += 1\n",
    "        \n",
    "    while centroides.shape[0] > num_rbfs:\n",
    "        centroides = centroides[np.random.choice(centroides.shape[0], num_rbfs,0),:]\n",
    "    return centroides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Declaramos la función para calcular los radios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_radios(centros, num_rbfs):\n",
    "    \"\"\" Calcula el valor de los radios tras el clustering.\n",
    "        Recibe los siguientes parámetros:\n",
    "            - centros: conjunto de centroides.\n",
    "            - num_rbf: número de neuronas de tipo RBF.\n",
    "        Devuelve:\n",
    "            - radios: vector (num_rbf) con el radio de cada RBF.\n",
    "    \"\"\"\n",
    "\n",
    "    distancias_centros = squareform(pdist(centros, 'euclidean'))\n",
    "    radios = distancias_centros.sum(axis=1)\n",
    "    radios = radios/(2*num_rbfs-1)\n",
    "    return radios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Declaramos la función para calcular la matriz de salidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_matriz_r(distancias, radios):\n",
    "    \"\"\" Devuelve el valor de activación de cada neurona para cada patrón \n",
    "        (matriz R en la presentación)\n",
    "        Recibe los siguientes parámetros:\n",
    "            - distancias: matriz (num_patrones x num_rbf) con la distancia \n",
    "              desde cada patrón hasta cada rbf.\n",
    "            - radios: array (num_rbf) con el radio de cada RBF.\n",
    "        Devuelve:\n",
    "            - matriz_r: matriz (num_patrones x (num_rbf+1)) con el valor de \n",
    "              activación (out) de cada RBF para cada patrón. Además, añadimos\n",
    "              al final, en la última columna, un vector con todos los \n",
    "              valores a 1, que actuará como sesgo.\n",
    "    \"\"\"\n",
    "    matriz_r = np.ones(shape = (distancias.shape[0], distancias.shape[1]+1))\n",
    "    matriz_r[:,:-1] =  np.exp(-(distancias**2)/(2*(np.power(radios, 2))))\n",
    "\n",
    "    return matriz_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Declaramos la función para invertir la matriz R cuando estamos en regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invertir_matriz_regresion(matriz_r, train_outputs):\n",
    "    \"\"\" Devuelve el vector de coeficientes obtenidos para el caso de la \n",
    "        regresión (matriz beta en las diapositivas)\n",
    "        Recibe los siguientes parámetros:\n",
    "            - matriz_r: matriz (num_patrones x (num_rbf+1)) con el valor de \n",
    "              activación (out) de cada RBF para cada patrón. Además, añadimos\n",
    "              al final, en la última columna, un vector con todos los \n",
    "              valores a 1, que actuará como sesgo.\n",
    "            - train_outputs: matriz con las variables de salida de \n",
    "              entrenamiento.\n",
    "        Devuelve:\n",
    "            - coeficientes: vector (num_rbf+1) con el valor del sesgo y del \n",
    "              coeficiente de salida para cada rbf.\n",
    "    \"\"\"\n",
    "    coefficients = np.transpose(np.dot(np.linalg.pinv(matriz_r), train_outputs))\n",
    "\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Declaramos la función para calcular la regresión logística L1 o L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_clasificacion(matriz_r, train_outputs, eta, l2):\n",
    "    \"\"\" Devuelve el objeto de tipo regresión logística obtenido a partir de la\n",
    "        matriz R.\n",
    "        Recibe los siguientes parámetros:\n",
    "            - matriz_r: matriz (num_patrones x (num_rbf+1)) con el valor de \n",
    "              activación (out) de cada RBF para cada patrón. Además, añadimos\n",
    "              al final, en la última columna, un vector con todos los \n",
    "              valores a 1, que actuará como sesgo.\n",
    "            - train_outputs: matriz con las variables de salida de \n",
    "              entrenamiento.\n",
    "            - eta: valor del parámetro de regularización para la Regresión \n",
    "              Logística.\n",
    "            - l2: True si queremos utilizar L2 para la Regresión Logística. \n",
    "              False si queremos usar L1.\n",
    "        Devuelve:\n",
    "            - logreg: objeto de tipo sklearn.linear_model.LogisticRegression ya\n",
    "              entrenado.\n",
    "    \"\"\"\n",
    "\n",
    "    if l2 == True:\n",
    "        logreg = LogisticRegression(penalty='l2', C=1/eta, solver='liblinear', fit_intercept=False).fit(matriz_r,train_outputs)\n",
    "    else:\n",
    "        logreg = LogisticRegression(penalty='l1', C=1/eta, solver='liblinear', fit_intercept=False).fit(matriz_r,train_outputs)\n",
    "    \n",
    "    return logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_data.sort_values(by=0).values[:,0], train_data.sort_values(by=0).values[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
